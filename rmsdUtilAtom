def rmsdUtilAtom(df: Dataset[PDB],atomName:String, startFrame:Int,spark: SparkSession) : RDD[Double] = {
    import spark.implicits._
    val sc = spark.sparkContext
    var dfarr = new Array[DataFrame](10)
    var rmsdArr = new Array[Double](10)
    for(i<-0 to 9) {
      val temp = df.where($"atom" <= atomName && $"frame_no" === startFrame+i).select( $"X", $"Y", $"Z")
      dfarr(i) = temp
    }
    //var rmsdSum :Double = 0
    for(i<-1 to dfarr.length -1) {
      var P: SimpleMatrix = matrix(dfarr(0), spark)
      var Q: SimpleMatrix = matrix(dfarr(i), spark)
      var kb: Kabsch = new Kabsch(P, Q)
      var Pcentroid = kb.getCentroids.get("P")
      var Ccentroid = kb.getCentroids.get("Q")
      //println(Pcentroid)
      var result = kb.tranl(P,Q,Pcentroid,Ccentroid)
      P = result.get("P")
      Q = result.get("Q")
      kb = new Kabsch(P,Q)
      kb.calculate()
      val R = kb.rotation
      P = P.mult(R)
      rmsdArr(i)= rmsd(P,Q)
    }
    return sc.parallelize(rmsdArr)
  }
  def rmsd(V : SimpleMatrix , W :SimpleMatrix): Double = {
    val D = V.numCols()
    val N = V.getNumElements
    var result = 0.0
    for(i <- 0 to V.numRows()-1)
    {
      var temp:Double = 0
      for(j <- 0 to 2)
      {
        result += (W.get(i,j) - V.get(i,j)) * (W.get(i,j) - V.get(i,j))
      }
    }

    math.sqrt(result/N)
  }

  def matrix(df:Dataset[Row],spark: SparkSession):SimpleMatrix = {
    var arr= df.collect()
    var mat = new SimpleMatrix(arr.length,3)
    //var mat = Array.ofDim[Double](arr.length, 3)
    for(i<- 0 to arr.length-1){

      mat.set(i,0,arr(i)(0).toString.toDouble)
      mat.set(i,1,arr(i)(1).toString.toDouble)
      mat.set(i,2,arr(i)(2).toString.toDouble)
      //mat.get(i,1)=arr(i)(1).toString.toDouble
      //mat.get(i,2)=arr(i)(2).toString.toDouble

    }
    mat
  }
